{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "- Split the dataset `70-30` ratio\n",
    "- Null values have been replaced with `mean`\n",
    "- Highest accuracy: `('LightGBM', 0.8792738688323211)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import my_packages as mypckg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/adult.csv', na_values=\"?\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the dataset\n",
    "df , mappings = mypckg.encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"workclass\": {\n",
      "        \"Private\": 0,\n",
      "        \"Local-gov\": 1,\n",
      "        \"Self-emp-not-inc\": 2,\n",
      "        \"Federal-gov\": 3,\n",
      "        \"State-gov\": 4,\n",
      "        \"Self-emp-inc\": 5,\n",
      "        \"Without-pay\": 6,\n",
      "        \"Never-worked\": 7\n",
      "    },\n",
      "    \"education\": {\n",
      "        \"11th\": 0,\n",
      "        \"HS-grad\": 1,\n",
      "        \"Assoc-acdm\": 2,\n",
      "        \"Some-college\": 3,\n",
      "        \"10th\": 4,\n",
      "        \"Prof-school\": 5,\n",
      "        \"7th-8th\": 6,\n",
      "        \"Bachelors\": 7,\n",
      "        \"Masters\": 8,\n",
      "        \"Doctorate\": 9,\n",
      "        \"5th-6th\": 10,\n",
      "        \"Assoc-voc\": 11,\n",
      "        \"9th\": 12,\n",
      "        \"12th\": 13,\n",
      "        \"1st-4th\": 14,\n",
      "        \"Preschool\": 15\n",
      "    },\n",
      "    \"marital-status\": {\n",
      "        \"Never-married\": 0,\n",
      "        \"Married-civ-spouse\": 1,\n",
      "        \"Widowed\": 2,\n",
      "        \"Divorced\": 3,\n",
      "        \"Separated\": 4,\n",
      "        \"Married-spouse-absent\": 5,\n",
      "        \"Married-AF-spouse\": 6\n",
      "    },\n",
      "    \"occupation\": {\n",
      "        \"Machine-op-inspct\": 0,\n",
      "        \"Farming-fishing\": 1,\n",
      "        \"Protective-serv\": 2,\n",
      "        \"Other-service\": 3,\n",
      "        \"Prof-specialty\": 4,\n",
      "        \"Craft-repair\": 5,\n",
      "        \"Adm-clerical\": 6,\n",
      "        \"Exec-managerial\": 7,\n",
      "        \"Tech-support\": 8,\n",
      "        \"Sales\": 9,\n",
      "        \"Priv-house-serv\": 10,\n",
      "        \"Transport-moving\": 11,\n",
      "        \"Handlers-cleaners\": 12,\n",
      "        \"Armed-Forces\": 13\n",
      "    },\n",
      "    \"relationship\": {\n",
      "        \"Own-child\": 0,\n",
      "        \"Husband\": 1,\n",
      "        \"Not-in-family\": 2,\n",
      "        \"Unmarried\": 3,\n",
      "        \"Wife\": 4,\n",
      "        \"Other-relative\": 5\n",
      "    },\n",
      "    \"race\": {\n",
      "        \"Black\": 0,\n",
      "        \"White\": 1,\n",
      "        \"Asian-Pac-Islander\": 2,\n",
      "        \"Other\": 3,\n",
      "        \"Amer-Indian-Eskimo\": 4\n",
      "    },\n",
      "    \"gender\": {\n",
      "        \"Male\": 0,\n",
      "        \"Female\": 1\n",
      "    },\n",
      "    \"native-country\": {\n",
      "        \"United-States\": 0,\n",
      "        \"Peru\": 1,\n",
      "        \"Guatemala\": 2,\n",
      "        \"Mexico\": 3,\n",
      "        \"Dominican-Republic\": 4,\n",
      "        \"Ireland\": 5,\n",
      "        \"Germany\": 6,\n",
      "        \"Philippines\": 7,\n",
      "        \"Thailand\": 8,\n",
      "        \"Haiti\": 9,\n",
      "        \"El-Salvador\": 10,\n",
      "        \"Puerto-Rico\": 11,\n",
      "        \"Vietnam\": 12,\n",
      "        \"South\": 13,\n",
      "        \"Columbia\": 14,\n",
      "        \"Japan\": 15,\n",
      "        \"India\": 16,\n",
      "        \"Cambodia\": 17,\n",
      "        \"Poland\": 18,\n",
      "        \"Laos\": 19,\n",
      "        \"England\": 20,\n",
      "        \"Cuba\": 21,\n",
      "        \"Taiwan\": 22,\n",
      "        \"Italy\": 23,\n",
      "        \"Canada\": 24,\n",
      "        \"Portugal\": 25,\n",
      "        \"China\": 26,\n",
      "        \"Nicaragua\": 27,\n",
      "        \"Honduras\": 28,\n",
      "        \"Iran\": 29,\n",
      "        \"Scotland\": 30,\n",
      "        \"Jamaica\": 31,\n",
      "        \"Ecuador\": 32,\n",
      "        \"Yugoslavia\": 33,\n",
      "        \"Hungary\": 34,\n",
      "        \"Hong\": 35,\n",
      "        \"Greece\": 36,\n",
      "        \"Trinadad&Tobago\": 37,\n",
      "        \"Outlying-US(Guam-USVI-etc)\": 38,\n",
      "        \"France\": 39,\n",
      "        \"Holand-Netherlands\": 40\n",
      "    },\n",
      "    \"income\": {\n",
      "        \"<=50K\": 0,\n",
      "        \">50K\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mypckg.show(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature and Target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('income', axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0       25        0.0  226802          0                7               0   \n",
      "1       38        0.0   89814          1                9               1   \n",
      "2       28        1.0  336951          2               12               1   \n",
      "3       44        0.0  160323          3               10               1   \n",
      "4       18        NaN  103497          3               10               0   \n",
      "...    ...        ...     ...        ...              ...             ...   \n",
      "48837   27        0.0  257302          2               12               1   \n",
      "48838   40        0.0  154374          1                9               1   \n",
      "48839   58        0.0  151910          1                9               2   \n",
      "48840   22        0.0  201490          1                9               0   \n",
      "48841   52        5.0  287927          1                9               1   \n",
      "\n",
      "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0             0.0             0     0       0             0             0   \n",
      "1             1.0             1     1       0             0             0   \n",
      "2             2.0             1     1       0             0             0   \n",
      "3             0.0             1     0       0          7688             0   \n",
      "4             NaN             0     1       1             0             0   \n",
      "...           ...           ...   ...     ...           ...           ...   \n",
      "48837         8.0             4     1       1             0             0   \n",
      "48838         0.0             1     1       0             0             0   \n",
      "48839         6.0             3     1       1             0             0   \n",
      "48840         6.0             0     1       0             0             0   \n",
      "48841         7.0             4     1       1         15024             0   \n",
      "\n",
      "       hours-per-week  native-country  \n",
      "0                  40             0.0  \n",
      "1                  50             0.0  \n",
      "2                  40             0.0  \n",
      "3                  40             0.0  \n",
      "4                  30             0.0  \n",
      "...               ...             ...  \n",
      "48837              38             0.0  \n",
      "48838              40             0.0  \n",
      "48839              40             0.0  \n",
      "48840              20             0.0  \n",
      "48841              40             0.0  \n",
      "\n",
      "[48842 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "48837    0\n",
      "48838    1\n",
      "48839    0\n",
      "48840    0\n",
      "48841    1\n",
      "Name: income, Length: 48842, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 14)\n",
      "(34189,)\n",
      "(14653, 14)\n",
      "(14653,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                   0\n",
      "workclass          1969\n",
      "fnlwgt                0\n",
      "education             0\n",
      "educational-num       0\n",
      "marital-status        0\n",
      "occupation         1977\n",
      "relationship          0\n",
      "race                  0\n",
      "gender                0\n",
      "capital-gain          0\n",
      "capital-loss          0\n",
      "hours-per-week        0\n",
      "native-country      585\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass          830\n",
      "fnlwgt               0\n",
      "education            0\n",
      "educational-num      0\n",
      "marital-status       0\n",
      "occupation         832\n",
      "relationship         0\n",
      "race                 0\n",
      "gender               0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     272\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                0\n",
      "workclass          0\n",
      "fnlwgt             0\n",
      "education          0\n",
      "educational-num    0\n",
      "marital-status     0\n",
      "occupation         0\n",
      "relationship       0\n",
      "race               0\n",
      "gender             0\n",
      "capital-gain       0\n",
      "capital-loss       0\n",
      "hours-per-week     0\n",
      "native-country     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(X_train.mean(),inplace=True)\n",
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                0\n",
      "workclass          0\n",
      "fnlwgt             0\n",
      "education          0\n",
      "educational-num    0\n",
      "marital-status     0\n",
      "occupation         0\n",
      "relationship       0\n",
      "race               0\n",
      "gender             0\n",
      "capital-gain       0\n",
      "capital-loss       0\n",
      "hours-per-week     0\n",
      "native-country     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_test.fillna(X_train.mean(), inplace=True)\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allign the y_train and y_test according to the indecies of X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.loc[X_train.index]\n",
    "y_test= y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(max_iter=1000),\n",
       " 'Decision Tree': DecisionTreeClassifier(),\n",
       " 'Random Forest': RandomForestClassifier(),\n",
       " 'Support Vector Classifier': SVC(),\n",
       " 'Naive Bayes': GaussianNB(),\n",
       " 'Gradient Boosting': GradientBoostingClassifier(),\n",
       " 'AdaBoost': AdaBoostClassifier(),\n",
       " 'LightGBM': LGBMClassifier(),\n",
       " 'XGBoost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=None, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "               n_jobs=None, num_parallel_tree=None, random_state=None, ...),\n",
       " 'KNeighbors': KNeighborsClassifier(),\n",
       " 'Bagging': BaggingClassifier()}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = mypckg.get_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\codes\\data-analysis\\adult-income-prediction\\env-adult-income-prediction\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8029072544871357\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88     11233\n",
      "           1       0.68      0.30      0.41      3420\n",
      "\n",
      "    accuracy                           0.80     14653\n",
      "   macro avg       0.75      0.63      0.65     14653\n",
      "weighted avg       0.78      0.80      0.77     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10754   479]\n",
      " [ 2409  1011]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Logistic Regression: 0.8029072544871357\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.817716508564799\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     11233\n",
      "           1       0.60      0.64      0.62      3420\n",
      "\n",
      "    accuracy                           0.82     14653\n",
      "   macro avg       0.75      0.76      0.75     14653\n",
      "weighted avg       0.82      0.82      0.82     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9797 1436]\n",
      " [1235 2185]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Decision Tree: 0.817716508564799\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8643963693441616\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     11233\n",
      "           1       0.74      0.64      0.69      3420\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.82      0.79      0.80     14653\n",
      "weighted avg       0.86      0.86      0.86     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10472   761]\n",
      " [ 1226  2194]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Random Forest: 0.8643963693441616\n",
      "\n",
      "\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.8041356718760664\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89     11233\n",
      "           1       0.96      0.17      0.29      3420\n",
      "\n",
      "    accuracy                           0.80     14653\n",
      "   macro avg       0.88      0.58      0.59     14653\n",
      "weighted avg       0.84      0.80      0.75     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11210    23]\n",
      " [ 2847   573]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Support Vector Classifier: 0.8041356718760664\n",
      "\n",
      "\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.8000409472462977\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88     11233\n",
      "           1       0.65      0.31      0.42      3420\n",
      "\n",
      "    accuracy                           0.80     14653\n",
      "   macro avg       0.73      0.63      0.65     14653\n",
      "weighted avg       0.78      0.80      0.77     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10653   580]\n",
      " [ 2350  1070]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Naive Bayes: 0.8000409472462977\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.8725858186036989\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     11233\n",
      "           1       0.80      0.61      0.69      3420\n",
      "\n",
      "    accuracy                           0.87     14653\n",
      "   macro avg       0.84      0.78      0.80     14653\n",
      "weighted avg       0.87      0.87      0.87     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10710   523]\n",
      " [ 1344  2076]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Gradient Boosting: 0.8725858186036989\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\codes\\data-analysis\\adult-income-prediction\\env-adult-income-prediction\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoost\n",
      "Accuracy: 0.863167951955231\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     11233\n",
      "           1       0.76      0.61      0.67      3420\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.82      0.77      0.79     14653\n",
      "weighted avg       0.86      0.86      0.86     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10570   663]\n",
      " [ 1342  2078]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for AdaBoost: 0.863167951955231\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 8267, number of negative: 25922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 710\n",
      "[LightGBM] [Info] Number of data points in the train set: 34189, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241803 -> initscore=-1.142820\n",
      "[LightGBM] [Info] Start training from score -1.142820\n",
      "Model: LightGBM\n",
      "Accuracy: 0.8792738688323211\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     11233\n",
      "           1       0.78      0.67      0.72      3420\n",
      "\n",
      "    accuracy                           0.88     14653\n",
      "   macro avg       0.84      0.81      0.82     14653\n",
      "weighted avg       0.88      0.88      0.88     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10580   653]\n",
      " [ 1116  2304]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for LightGBM: 0.8792738688323211\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.8779772060328943\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     11233\n",
      "           1       0.77      0.67      0.72      3420\n",
      "\n",
      "    accuracy                           0.88     14653\n",
      "   macro avg       0.84      0.81      0.82     14653\n",
      "weighted avg       0.87      0.88      0.87     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10561   672]\n",
      " [ 1116  2304]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for XGBoost: 0.8779772060328943\n",
      "\n",
      "\n",
      "Model: KNeighbors\n",
      "Accuracy: 0.7803862690234081\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87     11233\n",
      "           1       0.55      0.33      0.41      3420\n",
      "\n",
      "    accuracy                           0.78     14653\n",
      "   macro avg       0.68      0.62      0.64     14653\n",
      "weighted avg       0.76      0.78      0.76     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10311   922]\n",
      " [ 2296  1124]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for KNeighbors: 0.7803862690234081\n",
      "\n",
      "\n",
      "Model: Bagging\n",
      "Accuracy: 0.856548147137105\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     11233\n",
      "           1       0.73      0.60      0.66      3420\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.81      0.77      0.79     14653\n",
      "weighted avg       0.85      0.86      0.85     14653\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10486   747]\n",
      " [ 1355  2065]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Bagging: 0.856548147137105\n",
      "\n",
      "\n",
      "All the accuracies:\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "{\n",
      "    \"Logistic Regression\": 0.8029072544871357,\n",
      "    \"Decision Tree\": 0.817716508564799,\n",
      "    \"Random Forest\": 0.8643963693441616,\n",
      "    \"Support Vector Classifier\": 0.8041356718760664,\n",
      "    \"Naive Bayes\": 0.8000409472462977,\n",
      "    \"Gradient Boosting\": 0.8725858186036989,\n",
      "    \"AdaBoost\": 0.863167951955231,\n",
      "    \"LightGBM\": 0.8792738688323211,\n",
      "    \"XGBoost\": 0.8779772060328943,\n",
      "    \"KNeighbors\": 0.7803862690234081,\n",
      "    \"Bagging\": 0.856548147137105\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "accuracies = mypckg.run_the_models(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The higest accuracy in this experiment:\n",
      "LightGBM -->> 0.8792738688323211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('LightGBM', 0.8792738688323211)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypckg.highest_accuracy(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-adult-income-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
