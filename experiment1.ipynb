{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "\n",
    "- No preprocessing steps. Just rows with null values have been removed.\n",
    "- Highest Accuracy: `('LightGBM', 0.8768075946572469)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import my_packages as mypckg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/adult.csv', na_values=\"?\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the dataset\n",
    "df , mappings = mypckg.encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"workclass\": {\n",
      "        \"Private\": 0,\n",
      "        \"Local-gov\": 1,\n",
      "        \"Self-emp-not-inc\": 2,\n",
      "        \"Federal-gov\": 3,\n",
      "        \"State-gov\": 4,\n",
      "        \"Self-emp-inc\": 5,\n",
      "        \"Without-pay\": 6,\n",
      "        \"Never-worked\": 7\n",
      "    },\n",
      "    \"education\": {\n",
      "        \"11th\": 0,\n",
      "        \"HS-grad\": 1,\n",
      "        \"Assoc-acdm\": 2,\n",
      "        \"Some-college\": 3,\n",
      "        \"10th\": 4,\n",
      "        \"Prof-school\": 5,\n",
      "        \"7th-8th\": 6,\n",
      "        \"Bachelors\": 7,\n",
      "        \"Masters\": 8,\n",
      "        \"Doctorate\": 9,\n",
      "        \"5th-6th\": 10,\n",
      "        \"Assoc-voc\": 11,\n",
      "        \"9th\": 12,\n",
      "        \"12th\": 13,\n",
      "        \"1st-4th\": 14,\n",
      "        \"Preschool\": 15\n",
      "    },\n",
      "    \"marital-status\": {\n",
      "        \"Never-married\": 0,\n",
      "        \"Married-civ-spouse\": 1,\n",
      "        \"Widowed\": 2,\n",
      "        \"Divorced\": 3,\n",
      "        \"Separated\": 4,\n",
      "        \"Married-spouse-absent\": 5,\n",
      "        \"Married-AF-spouse\": 6\n",
      "    },\n",
      "    \"occupation\": {\n",
      "        \"Machine-op-inspct\": 0,\n",
      "        \"Farming-fishing\": 1,\n",
      "        \"Protective-serv\": 2,\n",
      "        \"Other-service\": 3,\n",
      "        \"Prof-specialty\": 4,\n",
      "        \"Craft-repair\": 5,\n",
      "        \"Adm-clerical\": 6,\n",
      "        \"Exec-managerial\": 7,\n",
      "        \"Tech-support\": 8,\n",
      "        \"Sales\": 9,\n",
      "        \"Priv-house-serv\": 10,\n",
      "        \"Transport-moving\": 11,\n",
      "        \"Handlers-cleaners\": 12,\n",
      "        \"Armed-Forces\": 13\n",
      "    },\n",
      "    \"relationship\": {\n",
      "        \"Own-child\": 0,\n",
      "        \"Husband\": 1,\n",
      "        \"Not-in-family\": 2,\n",
      "        \"Unmarried\": 3,\n",
      "        \"Wife\": 4,\n",
      "        \"Other-relative\": 5\n",
      "    },\n",
      "    \"race\": {\n",
      "        \"Black\": 0,\n",
      "        \"White\": 1,\n",
      "        \"Asian-Pac-Islander\": 2,\n",
      "        \"Other\": 3,\n",
      "        \"Amer-Indian-Eskimo\": 4\n",
      "    },\n",
      "    \"gender\": {\n",
      "        \"Male\": 0,\n",
      "        \"Female\": 1\n",
      "    },\n",
      "    \"native-country\": {\n",
      "        \"United-States\": 0,\n",
      "        \"Peru\": 1,\n",
      "        \"Guatemala\": 2,\n",
      "        \"Mexico\": 3,\n",
      "        \"Dominican-Republic\": 4,\n",
      "        \"Ireland\": 5,\n",
      "        \"Germany\": 6,\n",
      "        \"Philippines\": 7,\n",
      "        \"Thailand\": 8,\n",
      "        \"Haiti\": 9,\n",
      "        \"El-Salvador\": 10,\n",
      "        \"Puerto-Rico\": 11,\n",
      "        \"Vietnam\": 12,\n",
      "        \"South\": 13,\n",
      "        \"Columbia\": 14,\n",
      "        \"Japan\": 15,\n",
      "        \"India\": 16,\n",
      "        \"Cambodia\": 17,\n",
      "        \"Poland\": 18,\n",
      "        \"Laos\": 19,\n",
      "        \"England\": 20,\n",
      "        \"Cuba\": 21,\n",
      "        \"Taiwan\": 22,\n",
      "        \"Italy\": 23,\n",
      "        \"Canada\": 24,\n",
      "        \"Portugal\": 25,\n",
      "        \"China\": 26,\n",
      "        \"Nicaragua\": 27,\n",
      "        \"Honduras\": 28,\n",
      "        \"Iran\": 29,\n",
      "        \"Scotland\": 30,\n",
      "        \"Jamaica\": 31,\n",
      "        \"Ecuador\": 32,\n",
      "        \"Yugoslavia\": 33,\n",
      "        \"Hungary\": 34,\n",
      "        \"Hong\": 35,\n",
      "        \"Greece\": 36,\n",
      "        \"Trinadad&Tobago\": 37,\n",
      "        \"Outlying-US(Guam-USVI-etc)\": 38,\n",
      "        \"France\": 39,\n",
      "        \"Holand-Netherlands\": 40\n",
      "    },\n",
      "    \"income\": {\n",
      "        \"<=50K\": 0,\n",
      "        \">50K\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mypckg.show(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature and Target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('income', axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0       25        0.0  226802          0                7               0   \n",
      "1       38        0.0   89814          1                9               1   \n",
      "2       28        1.0  336951          2               12               1   \n",
      "3       44        0.0  160323          3               10               1   \n",
      "4       18        NaN  103497          3               10               0   \n",
      "...    ...        ...     ...        ...              ...             ...   \n",
      "48837   27        0.0  257302          2               12               1   \n",
      "48838   40        0.0  154374          1                9               1   \n",
      "48839   58        0.0  151910          1                9               2   \n",
      "48840   22        0.0  201490          1                9               0   \n",
      "48841   52        5.0  287927          1                9               1   \n",
      "\n",
      "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0             0.0             0     0       0             0             0   \n",
      "1             1.0             1     1       0             0             0   \n",
      "2             2.0             1     1       0             0             0   \n",
      "3             0.0             1     0       0          7688             0   \n",
      "4             NaN             0     1       1             0             0   \n",
      "...           ...           ...   ...     ...           ...           ...   \n",
      "48837         8.0             4     1       1             0             0   \n",
      "48838         0.0             1     1       0             0             0   \n",
      "48839         6.0             3     1       1             0             0   \n",
      "48840         6.0             0     1       0             0             0   \n",
      "48841         7.0             4     1       1         15024             0   \n",
      "\n",
      "       hours-per-week  native-country  \n",
      "0                  40             0.0  \n",
      "1                  50             0.0  \n",
      "2                  40             0.0  \n",
      "3                  40             0.0  \n",
      "4                  30             0.0  \n",
      "...               ...             ...  \n",
      "48837              38             0.0  \n",
      "48838              40             0.0  \n",
      "48839              40             0.0  \n",
      "48840              20             0.0  \n",
      "48841              40             0.0  \n",
      "\n",
      "[48842 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "48837    0\n",
      "48838    1\n",
      "48839    0\n",
      "48840    0\n",
      "48841    1\n",
      "Name: income, Length: 48842, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39073, 14)\n",
      "(39073,)\n",
      "(9769, 14)\n",
      "(9769,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding and Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                   0\n",
      "workclass          2264\n",
      "fnlwgt                0\n",
      "education             0\n",
      "educational-num       0\n",
      "marital-status        0\n",
      "occupation         2273\n",
      "relationship          0\n",
      "race                  0\n",
      "gender                0\n",
      "capital-gain          0\n",
      "capital-loss          0\n",
      "hours-per-week        0\n",
      "native-country      671\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass          535\n",
      "fnlwgt               0\n",
      "education            0\n",
      "educational-num      0\n",
      "marital-status       0\n",
      "occupation         536\n",
      "relationship         0\n",
      "race                 0\n",
      "gender               0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     186\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                0\n",
      "workclass          0\n",
      "fnlwgt             0\n",
      "education          0\n",
      "educational-num    0\n",
      "marital-status     0\n",
      "occupation         0\n",
      "relationship       0\n",
      "race               0\n",
      "gender             0\n",
      "capital-gain       0\n",
      "capital-loss       0\n",
      "hours-per-week     0\n",
      "native-country     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                0\n",
      "workclass          0\n",
      "fnlwgt             0\n",
      "education          0\n",
      "educational-num    0\n",
      "marital-status     0\n",
      "occupation         0\n",
      "relationship       0\n",
      "race               0\n",
      "gender             0\n",
      "capital-gain       0\n",
      "capital-loss       0\n",
      "hours-per-week     0\n",
      "native-country     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_test.dropna(inplace=True)\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allign the y_train and y_test according to the indecies of X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.loc[X_train.index]\n",
    "y_test= y_test.loc[X_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(max_iter=1000),\n",
       " 'Decision Tree': DecisionTreeClassifier(),\n",
       " 'Random Forest': RandomForestClassifier(),\n",
       " 'Support Vector Classifier': SVC(),\n",
       " 'Naive Bayes': GaussianNB(),\n",
       " 'Gradient Boosting': GradientBoostingClassifier(),\n",
       " 'AdaBoost': AdaBoostClassifier(),\n",
       " 'LightGBM': LGBMClassifier(),\n",
       " 'XGBoost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=None, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "               n_jobs=None, num_parallel_tree=None, random_state=None, ...),\n",
       " 'KNeighbors': KNeighborsClassifier(),\n",
       " 'Bagging': BaggingClassifier()}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = mypckg.get_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\codes\\data-analysis\\adult-income-prediction\\env-adult-income-prediction\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.7939066122088531\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87      6867\n",
      "           1       0.66      0.31      0.42      2192\n",
      "\n",
      "    accuracy                           0.79      9059\n",
      "   macro avg       0.73      0.63      0.65      9059\n",
      "weighted avg       0.77      0.79      0.77      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6507  360]\n",
      " [1507  685]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Logistic Regression: 0.7939066122088531\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.8168672038856386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      6867\n",
      "           1       0.62      0.64      0.63      2192\n",
      "\n",
      "    accuracy                           0.82      9059\n",
      "   macro avg       0.75      0.76      0.75      9059\n",
      "weighted avg       0.82      0.82      0.82      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5993  874]\n",
      " [ 785 1407]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Decision Tree: 0.8168672038856386\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.861242962799426\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      6867\n",
      "           1       0.75      0.65      0.69      2192\n",
      "\n",
      "    accuracy                           0.86      9059\n",
      "   macro avg       0.82      0.79      0.80      9059\n",
      "weighted avg       0.86      0.86      0.86      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6382  485]\n",
      " [ 772 1420]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Random Forest: 0.861242962799426\n",
      "\n",
      "\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.7969974610884204\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      6867\n",
      "           1       0.96      0.17      0.29      2192\n",
      "\n",
      "    accuracy                           0.80      9059\n",
      "   macro avg       0.87      0.58      0.58      9059\n",
      "weighted avg       0.83      0.80      0.74      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6850   17]\n",
      " [1822  370]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Support Vector Classifier: 0.7969974610884204\n",
      "\n",
      "\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.7930235125289767\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87      6867\n",
      "           1       0.65      0.31      0.42      2192\n",
      "\n",
      "    accuracy                           0.79      9059\n",
      "   macro avg       0.73      0.63      0.65      9059\n",
      "weighted avg       0.77      0.79      0.76      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6508  359]\n",
      " [1516  676]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Naive Bayes: 0.7930235125289767\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.8686389226183906\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      6867\n",
      "           1       0.80      0.61      0.69      2192\n",
      "\n",
      "    accuracy                           0.87      9059\n",
      "   macro avg       0.84      0.78      0.81      9059\n",
      "weighted avg       0.86      0.87      0.86      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6522  345]\n",
      " [ 845 1347]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Gradient Boosting: 0.8686389226183906\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\codes\\data-analysis\\adult-income-prediction\\env-adult-income-prediction\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoost\n",
      "Accuracy: 0.8631195496191633\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      6867\n",
      "           1       0.77      0.62      0.69      2192\n",
      "\n",
      "    accuracy                           0.86      9059\n",
      "   macro avg       0.83      0.78      0.80      9059\n",
      "weighted avg       0.86      0.86      0.86      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6463  404]\n",
      " [ 836 1356]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for AdaBoost: 0.8631195496191633\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 9016, number of negative: 27147\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 703\n",
      "[LightGBM] [Info] Number of data points in the train set: 36163, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249316 -> initscore=-1.102266\n",
      "[LightGBM] [Info] Start training from score -1.102266\n",
      "Model: LightGBM\n",
      "Accuracy: 0.8768075946572469\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      6867\n",
      "           1       0.78      0.68      0.73      2192\n",
      "\n",
      "    accuracy                           0.88      9059\n",
      "   macro avg       0.84      0.81      0.82      9059\n",
      "weighted avg       0.87      0.88      0.87      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6451  416]\n",
      " [ 700 1492]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for LightGBM: 0.8768075946572469\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.873385583397726\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      6867\n",
      "           1       0.77      0.68      0.72      2192\n",
      "\n",
      "    accuracy                           0.87      9059\n",
      "   macro avg       0.84      0.81      0.82      9059\n",
      "weighted avg       0.87      0.87      0.87      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6420  447]\n",
      " [ 700 1492]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for XGBoost: 0.873385583397726\n",
      "\n",
      "\n",
      "Model: KNeighbors\n",
      "Accuracy: 0.7758030687713876\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      6867\n",
      "           1       0.56      0.35      0.43      2192\n",
      "\n",
      "    accuracy                           0.78      9059\n",
      "   macro avg       0.69      0.63      0.64      9059\n",
      "weighted avg       0.75      0.78      0.76      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6269  598]\n",
      " [1433  759]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for KNeighbors: 0.7758030687713876\n",
      "\n",
      "\n",
      "Model: Bagging\n",
      "Accuracy: 0.8525223534606469\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      6867\n",
      "           1       0.74      0.61      0.67      2192\n",
      "\n",
      "    accuracy                           0.85      9059\n",
      "   macro avg       0.81      0.77      0.79      9059\n",
      "weighted avg       0.85      0.85      0.85      9059\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6385  482]\n",
      " [ 854 1338]]\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Bagging: 0.8525223534606469\n",
      "\n",
      "\n",
      "All the accuracies:\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "{\n",
      "    \"Logistic Regression\": 0.7939066122088531,\n",
      "    \"Decision Tree\": 0.8168672038856386,\n",
      "    \"Random Forest\": 0.861242962799426,\n",
      "    \"Support Vector Classifier\": 0.7969974610884204,\n",
      "    \"Naive Bayes\": 0.7930235125289767,\n",
      "    \"Gradient Boosting\": 0.8686389226183906,\n",
      "    \"AdaBoost\": 0.8631195496191633,\n",
      "    \"LightGBM\": 0.8768075946572469,\n",
      "    \"XGBoost\": 0.873385583397726,\n",
      "    \"KNeighbors\": 0.7758030687713876,\n",
      "    \"Bagging\": 0.8525223534606469\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "accuracies = mypckg.run_the_models(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The higest accuracy in this experiment:\n",
      "LightGBM -->> 0.8768075946572469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('LightGBM', 0.8768075946572469)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypckg.highest_accuracy(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-adult-income-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
